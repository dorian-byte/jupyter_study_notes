{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5f2e20-d008-4cc9-bc7c-279dfc85ae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [1.         0.93333333 1.         0.93333333 0.93333333 0.93333333\n",
      " 0.93333333 0.93333333 1.         1.        ]\n",
      "Average Cross-Validation Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Initialize the model (Random Forest Classifier in this example)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "# Output the scores\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "\n",
    "# Calculate and output the average score\n",
    "average_score = scores.mean()\n",
    "print(\"Average Cross-Validation Score:\", average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dda7e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index: [ 1  2  3  5  6  7  8  9 11 13 14 15 16 17 19 20 21 23 24 25 26 27 28 29\n",
      " 32 34 35 36 37 38 40 41 42 43 46 47 48 49 50 51 52 54 55 56 57 58 59 60\n",
      " 61 62 63 64 65 66 67 68 69 71 72 74 75 78 79 81 82 84 85 86 87 88 89 91\n",
      " 92 93 94 95 96 97 98 99]\n",
      "test_index: [ 0  4 10 12 18 22 30 31 33 39 44 45 53 70 73 76 77 80 83 90]\n",
      "train_index: [ 0  1  2  3  4  6  7  8 10 12 13 14 17 18 19 20 21 22 23 24 25 27 29 30\n",
      " 31 32 33 34 36 37 38 39 41 43 44 45 46 48 49 50 51 52 53 54 56 57 58 59\n",
      " 60 61 62 63 64 67 68 70 71 73 74 75 76 77 78 79 80 81 82 83 84 86 87 89\n",
      " 90 91 92 94 95 97 98 99]\n",
      "test_index: [ 5  9 11 15 16 26 28 35 40 42 47 55 65 66 69 72 85 88 93 96]\n",
      "train_index: [ 0  1  2  4  5  9 10 11 12 14 15 16 18 20 21 22 23 26 28 29 30 31 32 33\n",
      " 35 37 39 40 41 42 43 44 45 46 47 48 50 51 52 53 54 55 56 57 58 59 60 61\n",
      " 63 65 66 67 68 69 70 71 72 73 74 75 76 77 79 80 82 83 84 85 86 87 88 90\n",
      " 91 92 93 94 96 97 98 99]\n",
      "test_index: [ 3  6  7  8 13 17 19 24 25 27 34 36 38 49 62 64 78 81 89 95]\n",
      "train_index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 33 34 35 36 37 38 39 40 42 44 45 47 49 51 52 53\n",
      " 55 60 62 63 64 65 66 69 70 71 72 73 74 76 77 78 80 81 82 83 84 85 86 87\n",
      " 88 89 90 91 92 93 95 96]\n",
      "test_index: [32 41 43 46 48 50 54 56 57 58 59 61 67 68 75 79 94 97 98 99]\n",
      "train_index: [ 0  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 22 24 25 26 27 28 30\n",
      " 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48 49 50 53 54 55 56 57\n",
      " 58 59 61 62 64 65 66 67 68 69 70 72 73 75 76 77 78 79 80 81 83 85 88 89\n",
      " 90 93 94 95 96 97 98 99]\n",
      "test_index: [ 1  2 14 20 21 23 29 37 51 52 60 63 71 74 82 84 86 87 91 92]\n",
      "Average In-Sample Error: 0.0\n",
      "Average Out-Of-Sample Error: 0.040000000000000036\n",
      "Difference between Out-Of-Sample Error and In-Sample Error: 0.040000000000000036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Generate a dataset\n",
    "X, y = make_classification(n_samples=100, n_features=20, random_state=42)\n",
    "\n",
    "# Create a model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "out_of_sample_scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "# Calculate in-sample error and out-of-sample error for each fold\n",
    "in_sample_errors = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"train_index:\",train_index)\n",
    "    print(\"test_index:\",test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate in-sample error\n",
    "    in_sample_error = np.mean((y_train - model.predict(X_train)) ** 2)\n",
    "    in_sample_errors.append(in_sample_error)\n",
    "\n",
    "# Calculate average in-sample error and out-of-sample error\n",
    "avg_in_sample_error = np.mean(in_sample_errors)\n",
    "avg_out_of_sample_error = 1 - np.mean(out_of_sample_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average In-Sample Error: {avg_in_sample_error}\")\n",
    "print(f\"Average Out-Of-Sample Error: {avg_out_of_sample_error}\")\n",
    "\n",
    "# Examine the difference\n",
    "difference = avg_out_of_sample_error - avg_in_sample_error\n",
    "print(f\"Difference between Out-Of-Sample Error and In-Sample Error: {difference}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f74477",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4194740",
   "metadata": {},
   "source": [
    "### Comparing in-sample vs out-of-sample error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dabf5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Validation Scores: [1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 0.8666666666666667, 1.0, 0.8666666666666667, 0.8, 1.0]\n",
      "Average Training Score: 1.0\n",
      "Average Validation Score: 0.9466666666666667\n",
      "The model may be overfitting\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Initialize the model (Random Forest Classifier in this example)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Number of folds\n",
    "num_folds = 10\n",
    "\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "# Store training and validation scores\n",
    "training_scores = []\n",
    "validation_scores = []\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "    training_scores.append(train_accuracy)\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(y_val, clf.predict(X_val))\n",
    "    validation_scores.append(val_accuracy)\n",
    "\n",
    "# Output the training and validation scores\n",
    "print(\"Training Scores:\", training_scores)\n",
    "print(\"Validation Scores:\", validation_scores)\n",
    "\n",
    "# Calculate and output the average scores\n",
    "average_train_score = np.mean(training_scores)\n",
    "average_val_score = np.mean(validation_scores)\n",
    "print(\"Average Training Score:\", average_train_score)\n",
    "print(\"Average Validation Score:\", average_val_score)\n",
    "\n",
    "# Check for overfitting\n",
    "if average_train_score > average_val_score:\n",
    "    print(\"The model may be overfitting\")\n",
    "else:\n",
    "    print(\"The model is not overfitting\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
